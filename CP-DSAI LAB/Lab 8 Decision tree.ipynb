{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025ea80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88690850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,predicted_class):\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "class Decisiontree:\n",
    "    def __init__(self,max_depth = None):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(set(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree_ = self.tree(X, y)\n",
    "\n",
    "    def find_split(self,X, y):\n",
    "        \"\"\" Find split where children has lowest impurity possible\n",
    "        in condition where the purity should also be less than the parent,\n",
    "        if not, stop.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "#         print(n_samples)\n",
    "        if n_samples <= 1:\n",
    "            return None, None\n",
    "\n",
    "        #so it will not have any warning about \"referenced before assignments\"\n",
    "        feature_ix, threshold = None, None\n",
    "\n",
    "        # Count of each class in the current node.\n",
    "        sample_per_class_parent = [np.sum(y == c) for c in range(self.n_classes)] #[2, 2]\n",
    "    #     print(sample_per_class_parent)\n",
    "\n",
    "        # Gini of parent node.\n",
    "        best_gini = 1.0 - sum((n / n_samples) ** 2 for n in sample_per_class_parent)\n",
    "    #     print(best_gini)\n",
    "\n",
    "        # Loop through all features.\n",
    "        for feature in range(self.n_features):\n",
    "\n",
    "            # Sort data along selected feature.\n",
    "            sample_sorted, y_sorted = zip(*sorted(zip(X[:, feature], y)))\n",
    "\n",
    "            sample_per_class_left = [0] * self.n_classes   #[0, 0]\n",
    "\n",
    "            sample_per_class_right = sample_per_class_parent.copy() #[2, 2]\n",
    "\n",
    "            #loop through each threshold, 2.5, 6.5, 14.5\n",
    "            #1st iter: [-] [-++]\n",
    "            #2nd iter: [--] [++]\n",
    "            #3rd iter: [--+] [+]\n",
    "            for i in range(1, n_samples): #1 to 3 (excluding 4)\n",
    "                #the class of that sample\n",
    "                c = y_sorted[i - 1]  #[0]\n",
    "\n",
    "                #put the sample to the left\n",
    "                sample_per_class_left[c] += 1  #[1, 0]\n",
    "    #             print(\"left\",sample_per_class_left)\n",
    "\n",
    "                #take the sample out from the right  [1, 2]\n",
    "                sample_per_class_right[c] -= 1\n",
    "    #             print(\"right\",sample_per_class_right)\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (sample_per_class_left[x] / i) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "\n",
    "                #we divided by n_samples - i since we know that the left amount of samples\n",
    "                #since left side has already i samples\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (sample_per_class_right[x] / (n_samples - i)) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "\n",
    "                #weighted gini\n",
    "                weighted_gini = ((i / n_samples) * gini_left) + ( (n_samples - i) /n_samples) * gini_right\n",
    "\n",
    "                # in case the value are the same, we do not split\n",
    "                # (both have to end up on the same side of a split).\n",
    "                if sample_sorted[i] == sample_sorted[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    feature_ix = feature\n",
    "                    threshold = (sample_sorted[i] + sample_sorted[i - 1]) / 2  # midpoint\n",
    "\n",
    "        #return the feature number and threshold \n",
    "        #used to find best split\n",
    "        return feature_ix, threshold\n",
    "    def tree(self,Xtrain, ytrain, depth=0):  \n",
    "        num_samples_per_class = [np.sum(ytrain == i) for i in range(self.n_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "\n",
    "        #define the parent node\n",
    "        node = Node(predicted_class=predicted_class)\n",
    "\n",
    "        #perform recursion\n",
    "        if depth < self.max_depth:\n",
    "            feature, threshold = self.find_split(Xtrain, ytrain)\n",
    "#         print(\"Best feature used for split: \", feature)\n",
    "#         print(\"Best threshold used for split: \", threshold)\n",
    "            if feature is not None:\n",
    "                #take all the indices that is less than threshold\n",
    "                indices_left = X[:, feature] < threshold\n",
    "    #             print(indices_left)\n",
    "    #             print(~indices_left)\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "    #             print(\"X_left is\",X_left)\n",
    "    #             print(\"y_left is\",y_left)\n",
    "\n",
    "                #tilde for negation\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "\n",
    "                #take note for later decision\n",
    "                node.feature_index = feature\n",
    "                node.threshold = threshold\n",
    "                node.left = self.tree(X_left, y_left, depth + 1)\n",
    "                node.right = self.tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff80e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()\n",
    "X, y = dataset.data, dataset.target\n",
    "model = Decisiontree(max_depth=10)\n",
    "model.fit(X, y)\n",
    "print(model.predict([[0, 0, 5, 1.5]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonDSAI",
   "language": "python",
   "name": "pythondsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
