{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e825f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e74ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=500, random_state=1)\n",
    "y = np.where(y==0,-1,1)  #change our y to be -1 if it is 0, otherwise 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67dabeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        # Determines whether threshold should be evaluated as < or >\n",
    "        self.polarity = 1\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        # Voting power of the stump\n",
    "        self.alpha = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b7c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, S=5, eta=0.5):\n",
    "        self.S = S\n",
    "        self.eta = eta\n",
    "        \n",
    "    def fit(self, X, y): #<----X_train, y_train\n",
    "        m, n = X.shape\n",
    "        \n",
    "        W = np.full(m, 1/m)\n",
    "                \n",
    "        self.clfs = []\n",
    "        \n",
    "        for _ in range(self.S):\n",
    "            clf = DecisionStump()\n",
    "            \n",
    "            min_err = np.inf\n",
    "\n",
    "            for feature in range(n):\n",
    "                feature_vals = np.sort(np.unique(X[:, feature]))\n",
    "                thresholds = (feature_vals[:-1] + feature_vals[1:])/2\n",
    "                for threshold in thresholds:\n",
    "                    for polarity in [1, -1]:\n",
    "                        yhat = np.ones(len(y)) #set all to 1\n",
    "                        yhat[polarity * X[:, feature] < polarity * threshold] = -1  \n",
    "                        err = W[(yhat != y)].sum()\n",
    "                                        \n",
    "                        #save the best stump\n",
    "                        if err < min_err:\n",
    "                            clf.polarity = polarity\n",
    "                            clf.threshold = threshold\n",
    "                            clf.feature_index = feature\n",
    "                            min_err = err\n",
    "#                             print(\"hello\")\n",
    "        \n",
    "            #once we know which is the best stump\n",
    "            #we calculate its alpha, and reweight samples\n",
    "            eps = 1e-10 #to prevent division by zero\n",
    "            clf.alpha = self.eta * (np.log ((1 - min_err) / (min_err + eps)))            \n",
    "            W = W * np.exp(-clf.alpha * y * yhat)\n",
    "            W = W / sum (W)\n",
    "\n",
    "            #save clf\n",
    "            self.clfs.append(clf)\n",
    "            print(f\"alpha for tree{_ + 1} is\",clf.alpha)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        m, n = X.shape\n",
    "        yhat = np.zeros(m)\n",
    "        for clf in self.clfs:\n",
    "            pred = np.ones(m) #set all to 1\n",
    "            pred[clf.polarity * X[:, clf.feature_index] < clf.polarity * clf.threshold] = -1 \n",
    "            yhat += clf.alpha * pred\n",
    "#             print((yhat))\n",
    "\n",
    "        return np.sign(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e95b29b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for tree1 is 1.4573816045379397\n",
      "alpha for tree2 is 1.9577842153322087\n",
      "alpha for tree3 is 3.8150839497502074\n",
      "alpha for tree4 is 7.62962075137483\n",
      "alpha for tree5 is 11.512647073166862\n",
      "alpha for tree6 is 11.5129254649702\n",
      "alpha for tree7 is 11.512925464970229\n",
      "alpha for tree8 is 11.512925464970229\n",
      "alpha for tree9 is 11.512925464970229\n",
      "alpha for tree10 is 11.512925464970229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.99      0.83        79\n",
      "           1       0.98      0.56      0.71        71\n",
      "\n",
      "    accuracy                           0.79       150\n",
      "   macro avg       0.85      0.78      0.77       150\n",
      "weighted avg       0.84      0.79      0.78       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoost(S=10)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(classification_report(y_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
